{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "emerging-wings",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "activated-technical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000e+00, 0.0000e+00, 1.8788e+31],\n",
      "         [1.7220e+22, 1.9152e+23, 1.0514e-05],\n",
      "         [4.2890e-08, 2.1345e-07, 4.3960e-05]],\n",
      "\n",
      "        [[1.3401e-08, 1.3667e+22, 2.1686e-04],\n",
      "         [2.4855e-18, 1.9421e+31, 2.7491e+20],\n",
      "         [6.1949e-04, 7.1856e+22, 4.3605e+27]],\n",
      "\n",
      "        [[2.3329e-18, 1.9284e+31, 3.2314e-18],\n",
      "         [4.1708e-08, 8.5826e-07, 2.1780e-04],\n",
      "         [2.6225e-09, 1.3108e-08, 1.3369e+22]],\n",
      "\n",
      "        [[1.0871e-05, 4.2699e-08, 2.3048e-12],\n",
      "         [1.1495e+24, 3.0881e+29, 2.5226e-18],\n",
      "         [4.2330e+21, 1.6534e+19, 3.0601e+32]],\n",
      "\n",
      "        [[3.3129e-18, 7.2646e+22, 7.2250e+28],\n",
      "         [2.5226e-18, 2.4148e-18, 2.6302e+20],\n",
      "         [6.1949e-04, 1.0256e-08, 6.4456e-10]]])\n",
      "****************************************************************************************************\n",
      "tensor([[-1.9878e-27,  4.5789e-41, -1.9878e-27],\n",
      "        [ 4.5789e-41,  4.4842e-44,  0.0000e+00],\n",
      "        [ 1.5695e-43,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 9.1835e-41,  0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "x=torch.Tensor(5,3,3)\n",
    "y=torch.Tensor(5,3)\n",
    "print(x)\n",
    "print('*'*100)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "capital-collaboration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0586, 0.3376, 0.6240],\n",
      "         [0.2136, 0.6321, 0.0505],\n",
      "         [0.6886, 0.3694, 0.9776]],\n",
      "\n",
      "        [[0.0440, 0.9404, 0.6757],\n",
      "         [0.9216, 0.8229, 0.2016],\n",
      "         [0.4109, 0.4402, 0.4411]],\n",
      "\n",
      "        [[0.2096, 0.2412, 0.9085],\n",
      "         [0.2355, 0.1957, 0.1495],\n",
      "         [0.0427, 0.3896, 0.5031]],\n",
      "\n",
      "        [[0.6144, 0.4793, 0.2995],\n",
      "         [0.5798, 0.9344, 0.1015],\n",
      "         [0.6543, 0.8568, 0.8742]],\n",
      "\n",
      "        [[0.2637, 0.3993, 0.9212],\n",
      "         [0.2203, 0.5098, 0.1799],\n",
      "         [0.1112, 0.7043, 0.8395]]])\n"
     ]
    }
   ],
   "source": [
    "x1=torch.rand(5,3,3)\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dress-railway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa3b6bb4910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "seasonal-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "naked-ireland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "requested-august",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5.8581e-02, 3.3762e-01, 1.8788e+31],\n",
      "         [1.7220e+22, 1.9152e+23, 5.0547e-02],\n",
      "         [6.8856e-01, 3.6936e-01, 9.7763e-01]],\n",
      "\n",
      "        [[4.3976e-02, 1.3667e+22, 6.7593e-01],\n",
      "         [9.2162e-01, 1.9421e+31, 2.7491e+20],\n",
      "         [4.1151e-01, 7.1856e+22, 4.3605e+27]],\n",
      "\n",
      "        [[2.0962e-01, 1.9284e+31, 9.0852e-01],\n",
      "         [2.3548e-01, 1.9569e-01, 1.4974e-01],\n",
      "         [4.2737e-02, 3.8961e-01, 1.3369e+22]],\n",
      "\n",
      "        [[6.1437e-01, 4.7926e-01, 2.9951e-01],\n",
      "         [1.1495e+24, 3.0881e+29, 1.0153e-01],\n",
      "         [4.2330e+21, 1.6534e+19, 3.0601e+32]],\n",
      "\n",
      "        [[2.6366e-01, 7.2646e+22, 7.2250e+28],\n",
      "         [2.2029e-01, 5.0977e-01, 2.6302e+20],\n",
      "         [1.1177e-01, 7.0429e-01, 8.3954e-01]]])\n"
     ]
    }
   ],
   "source": [
    "print(x+x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "decimal-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5.8581e-02, 3.3762e-01, 1.8788e+31],\n",
      "         [1.7220e+22, 1.9152e+23, 5.0547e-02],\n",
      "         [6.8856e-01, 3.6936e-01, 9.7763e-01]],\n",
      "\n",
      "        [[4.3976e-02, 1.3667e+22, 6.7593e-01],\n",
      "         [9.2162e-01, 1.9421e+31, 2.7491e+20],\n",
      "         [4.1151e-01, 7.1856e+22, 4.3605e+27]],\n",
      "\n",
      "        [[2.0962e-01, 1.9284e+31, 9.0852e-01],\n",
      "         [2.3548e-01, 1.9569e-01, 1.4974e-01],\n",
      "         [4.2737e-02, 3.8961e-01, 1.3369e+22]],\n",
      "\n",
      "        [[6.1437e-01, 4.7926e-01, 2.9951e-01],\n",
      "         [1.1495e+24, 3.0881e+29, 1.0153e-01],\n",
      "         [4.2330e+21, 1.6534e+19, 3.0601e+32]],\n",
      "\n",
      "        [[2.6366e-01, 7.2646e+22, 7.2250e+28],\n",
      "         [2.2029e-01, 5.0977e-01, 2.6302e+20],\n",
      "         [1.1177e-01, 7.0429e-01, 8.3954e-01]]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x,x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "polish-eating",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-a684708a1971>:2: UserWarning: An output with one or more elements was resized since it had shape [5, 3], which does not match the required output shape [5, 3, 3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
      "  torch.add(x,x1,out=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[5.8581e-02, 3.3762e-01, 1.8788e+31],\n",
       "         [1.7220e+22, 1.9152e+23, 5.0547e-02],\n",
       "         [6.8856e-01, 3.6936e-01, 9.7763e-01]],\n",
       "\n",
       "        [[4.3976e-02, 1.3667e+22, 6.7593e-01],\n",
       "         [9.2162e-01, 1.9421e+31, 2.7491e+20],\n",
       "         [4.1151e-01, 7.1856e+22, 4.3605e+27]],\n",
       "\n",
       "        [[2.0962e-01, 1.9284e+31, 9.0852e-01],\n",
       "         [2.3548e-01, 1.9569e-01, 1.4974e-01],\n",
       "         [4.2737e-02, 3.8961e-01, 1.3369e+22]],\n",
       "\n",
       "        [[6.1437e-01, 4.7926e-01, 2.9951e-01],\n",
       "         [1.1495e+24, 3.0881e+29, 1.0153e-01],\n",
       "         [4.2330e+21, 1.6534e+19, 3.0601e+32]],\n",
       "\n",
       "        [[2.6366e-01, 7.2646e+22, 7.2250e+28],\n",
       "         [2.2029e-01, 5.0977e-01, 2.6302e+20],\n",
       "         [1.1177e-01, 7.0429e-01, 8.3954e-01]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=torch.Tensor(5,3)\n",
    "torch.add(x,x1,out=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "thermal-commerce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function add:\n",
      "\n",
      "add(...)\n",
      "    add(input, other, *, out=None)\n",
      "    \n",
      "    Adds the scalar :attr:`other` to each element of the input :attr:`input`\n",
      "    and returns a new resulting tensor.\n",
      "    \n",
      "    .. math::\n",
      "        \\text{out} = \\text{input} + \\text{other}\n",
      "    \n",
      "    If :attr:`input` is of type FloatTensor or DoubleTensor, :attr:`other` must be\n",
      "    a real number, otherwise it should be an integer.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "        value (Number): the number to be added to each element of :attr:`input`\n",
      "    \n",
      "    Keyword arguments:\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(4)\n",
      "        >>> a\n",
      "        tensor([ 0.0202,  1.0985,  1.3506, -0.6056])\n",
      "        >>> torch.add(a, 20)\n",
      "        tensor([ 20.0202,  21.0985,  21.3506,  19.3944])\n",
      "    \n",
      "    .. function:: add(input, other, *, alpha=1, out=None)\n",
      "    \n",
      "    Each element of the tensor :attr:`other` is multiplied by the scalar\n",
      "    :attr:`alpha` and added to each element of the tensor :attr:`input`.\n",
      "    The resulting tensor is returned.\n",
      "    \n",
      "    The shapes of :attr:`input` and :attr:`other` must be\n",
      "    :ref:`broadcastable <broadcasting-semantics>`.\n",
      "    \n",
      "    .. math::\n",
      "        \\text{out} = \\text{input} + \\text{alpha} \\times \\text{other}\n",
      "    \n",
      "    If :attr:`other` is of type FloatTensor or DoubleTensor, :attr:`alpha` must be\n",
      "    a real number, otherwise it should be an integer.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the first input tensor\n",
      "        other (Tensor): the second input tensor\n",
      "    \n",
      "    Keyword args:\n",
      "        alpha (Number): the scalar multiplier for :attr:`other`\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(4)\n",
      "        >>> a\n",
      "        tensor([-0.9732, -0.3497,  0.6245,  0.4022])\n",
      "        >>> b = torch.randn(4, 1)\n",
      "        >>> b\n",
      "        tensor([[ 0.3743],\n",
      "                [-1.7724],\n",
      "                [-0.5811],\n",
      "                [-0.8017]])\n",
      "        >>> torch.add(a, b, alpha=10)\n",
      "        tensor([[  2.7695,   3.3930,   4.3672,   4.1450],\n",
      "                [-18.6971, -18.0736, -17.0994, -17.3216],\n",
      "                [ -6.7845,  -6.1610,  -5.1868,  -5.4090],\n",
      "                [ -8.9902,  -8.3667,  -7.3925,  -7.6147]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "undefined-player",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5.8581e-02, 3.3762e-01, 7.5151e+31],\n",
       "         [6.8879e+22, 7.6610e+23, 5.0578e-02],\n",
       "         [6.8856e-01, 3.6936e-01, 9.7777e-01]],\n",
       "\n",
       "        [[4.3976e-02, 5.4667e+22, 6.7658e-01],\n",
       "         [9.2162e-01, 7.7686e+31, 1.0996e+21],\n",
       "         [4.1337e-01, 2.8742e+23, 1.7442e+28]],\n",
       "\n",
       "        [[2.0962e-01, 7.7135e+31, 9.0852e-01],\n",
       "         [2.3548e-01, 1.9570e-01, 1.5039e-01],\n",
       "         [4.2737e-02, 3.8961e-01, 5.3477e+22]],\n",
       "\n",
       "        [[6.1440e-01, 4.7926e-01, 2.9951e-01],\n",
       "         [4.5982e+24, 1.2352e+30, 1.0153e-01],\n",
       "         [1.6932e+22, 6.6136e+19, 1.2240e+33]],\n",
       "\n",
       "        [[2.6366e-01, 2.9058e+23, 2.8900e+29],\n",
       "         [2.2029e-01, 5.0977e-01, 1.0521e+21],\n",
       "         [1.1363e-01, 7.0429e-01, 8.3954e-01]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.add_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "equal-semester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5.8581e-02, 3.3762e-01, 7.5151e+31],\n",
      "         [6.8879e+22, 7.6610e+23, 5.0578e-02],\n",
      "         [6.8856e-01, 3.6936e-01, 9.7777e-01]],\n",
      "\n",
      "        [[4.3976e-02, 5.4667e+22, 6.7658e-01],\n",
      "         [9.2162e-01, 7.7686e+31, 1.0996e+21],\n",
      "         [4.1337e-01, 2.8742e+23, 1.7442e+28]],\n",
      "\n",
      "        [[2.0962e-01, 7.7135e+31, 9.0852e-01],\n",
      "         [2.3548e-01, 1.9570e-01, 1.5039e-01],\n",
      "         [4.2737e-02, 3.8961e-01, 5.3477e+22]],\n",
      "\n",
      "        [[6.1440e-01, 4.7926e-01, 2.9951e-01],\n",
      "         [4.5982e+24, 1.2352e+30, 1.0153e-01],\n",
      "         [1.6932e+22, 6.6136e+19, 1.2240e+33]],\n",
      "\n",
      "        [[2.6366e-01, 2.9058e+23, 2.8900e+29],\n",
      "         [2.2029e-01, 5.0977e-01, 1.0521e+21],\n",
      "         [1.1363e-01, 7.0429e-01, 8.3954e-01]]])\n"
     ]
    }
   ],
   "source": [
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "configured-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ultimate-score",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b=a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "painful-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fifteen-saint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[5.8581e-02, 3.3762e-01, 9.3939e+31],\n",
      "         [8.6099e+22, 9.5762e+23, 5.0589e-02],\n",
      "         [6.8856e-01, 3.6936e-01, 9.7781e-01]],\n",
      "\n",
      "        [[4.3976e-02, 6.8334e+22, 6.7680e-01],\n",
      "         [9.2162e-01, 9.7107e+31, 1.3746e+21],\n",
      "         [4.1399e-01, 3.5928e+23, 2.1802e+28]],\n",
      "\n",
      "        [[2.0962e-01, 9.6419e+31, 9.0852e-01],\n",
      "         [2.3548e-01, 1.9570e-01, 1.5061e-01],\n",
      "         [4.2737e-02, 3.8961e-01, 6.6847e+22]],\n",
      "\n",
      "        [[6.1441e-01, 4.7926e-01, 2.9951e-01],\n",
      "         [5.7477e+24, 1.5440e+30, 1.0153e-01],\n",
      "         [2.1165e+22, 8.2670e+19, 1.5300e+33]],\n",
      "\n",
      "        [[2.6366e-01, 3.6323e+23, 3.6125e+29],\n",
      "         [2.2029e-01, 5.0977e-01, 1.3151e+21],\n",
      "         [1.1425e-01, 7.0429e-01, 8.3954e-01]]], device='cuda:0')\n",
      "time elapsed: 2.8947434425354004\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    tic=time.time()\n",
    "    x=x.cuda()\n",
    "    x1=x1.cuda()\n",
    "    toc=time.time()\n",
    "    print(x+x1)\n",
    "    print(\"time elapsed:\",toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aboriginal-metro",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "least-basics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x=Variable(torch.ones(2,2),requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "chief-sierra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y=x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "editorial-munich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<AddBackward0 object at 0x7fa3b667ebb0>\n"
     ]
    }
   ],
   "source": [
    "print(x.grad_fn)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "lyric-footage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=y*y*3\n",
    "out=z.mean()\n",
    "print(z,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "expanded-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "professional-emission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "tropical-investigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-522.1799, -338.9069, -824.4119], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3)\n",
    "x=Variable(x,requires_grad=True)\n",
    "\n",
    "y=x*2\n",
    "while y.data.norm()<1000:\n",
    "    y=y*2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "looking-camel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-796.2577, -879.9969, -417.2758])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "favorite-capability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1257.9905)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.data.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "altered-basket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
     ]
    }
   ],
   "source": [
    "gradients=torch.FloatTensor([.1,1,.0001])\n",
    "y.backward(gradients)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "finite-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "northern-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1=nn.Conv2d(1,6,5)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        self.fc1=nn.Linear(16*5*5,120)\n",
    "        self.fc2=nn.Linear(120,84)\n",
    "        self.fc3=nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x=x.view(-1,self.num_flat_features(x))\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        size=x.size()[1:]\n",
    "        num_feature=1\n",
    "        for s in size:\n",
    "            num_feature*=s\n",
    "        return num_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "danish-diagram",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net=Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "controversial-recorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "params=list(net.parameters())\n",
    "print(len(params))\n",
    "for p in params:\n",
    "    print(p.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Variable(torch.randn(1,32,32))\n",
    "out=net(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "native-wheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.1599, -0.0578, -1.0667,  0.4234,  0.8221],\n",
       "          [-1.5847,  0.7430,  1.1117, -0.7971,  0.3528],\n",
       "          [-1.1733,  0.1274, -0.9232,  0.1797, -1.3267],\n",
       "          [ 2.1427, -1.7916, -0.4263, -0.4933,  0.3366]],\n",
       "\n",
       "         [[ 1.4707,  1.7751,  0.9018,  0.2629,  0.3278],\n",
       "          [ 1.4871, -0.0230,  0.8194,  0.6683,  0.4530],\n",
       "          [-0.2491,  1.2711,  0.5827, -0.2567, -0.5475],\n",
       "          [-1.6884, -0.4888,  0.4217, -1.1865,  0.6107]],\n",
       "\n",
       "         [[-0.9295,  1.4089, -0.8317, -0.1894,  0.1853],\n",
       "          [-0.0857,  1.0721,  1.9575,  0.2716, -0.8825],\n",
       "          [ 0.5810, -0.2464,  0.2492,  1.0820,  0.5301],\n",
       "          [ 0.8598,  0.7942,  0.6760, -2.6037,  0.7029]]],\n",
       "\n",
       "\n",
       "        [[[-0.5543,  1.9725, -2.2014,  1.2452,  0.8144],\n",
       "          [-0.2874,  0.4540, -1.3864,  0.3143, -0.0357],\n",
       "          [ 1.1204, -0.1042,  0.0076,  0.0202, -0.0037],\n",
       "          [-2.6358, -0.2376,  0.0238,  0.0161, -0.6457]],\n",
       "\n",
       "         [[-0.2109,  1.0219,  0.6856, -0.1485,  1.0377],\n",
       "          [-1.2062, -0.7126,  0.9329,  0.5191, -0.5054],\n",
       "          [-1.4221, -0.7629, -0.2496, -1.3318,  0.4327],\n",
       "          [ 0.5468, -1.0718,  0.7367, -1.2024, -0.0435]],\n",
       "\n",
       "         [[-1.0994, -0.4927, -1.0294,  1.2420, -0.1861],\n",
       "          [-0.2720,  0.3064,  0.8952, -1.1945,  0.2491],\n",
       "          [ 1.1046, -0.2212,  0.1802, -1.3153, -1.8472],\n",
       "          [ 0.1402,  1.4413,  1.5035,  1.2805,  0.7940]]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "provincial-customs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "related-jacob",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Normalize in module torchvision.transforms.transforms:\n",
      "\n",
      "class Normalize(torch.nn.modules.module.Module)\n",
      " |  Normalize(mean, std, inplace=False)\n",
      " |  \n",
      " |  Normalize a tensor image with mean and standard deviation.\n",
      " |  Given mean: ``(mean[1],...,mean[n])`` and std: ``(std[1],..,std[n])`` for ``n``\n",
      " |  channels, this transform will normalize each channel of the input\n",
      " |  ``torch.*Tensor`` i.e.,\n",
      " |  ``output[channel] = (input[channel] - mean[channel]) / std[channel]``\n",
      " |  \n",
      " |  .. note::\n",
      " |      This transform acts out of place, i.e., it does not mutate the input tensor.\n",
      " |  \n",
      " |  Args:\n",
      " |      mean (sequence): Sequence of means for each channel.\n",
      " |      std (sequence): Sequence of standard deviations for each channel.\n",
      " |      inplace(bool,optional): Bool to make this operation in-place.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Normalize\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, mean, std, inplace=False)\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  forward(self, tensor: torch.Tensor) -> torch.Tensor\n",
      " |      Args:\n",
      " |          tensor (Tensor): Tensor image to be normalized.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Tensor: Normalized Tensor image.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__ = _call_impl(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      Default dir() implementation.\n",
      " |  \n",
      " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
      " |  \n",
      " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> @torch.no_grad()\n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  bfloat16(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf), buf.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self: ~T) -> ~T\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self: ~T) -> ~T\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  extra_repr(self) -> str\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should re-implement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  float(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self: ~T) -> ~T\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict: Dict[str, torch.Tensor], strict: bool = True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |  \n",
      " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param), param.size())\n",
      " |          <class 'torch.Tensor'> (20L,)\n",
      " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      .. warning ::\n",
      " |      \n",
      " |          The current implementation will not have the presented behavior\n",
      " |          for complex :class:`Module` that perform many operations.\n",
      " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
      " |          contain the gradients for a subset of the inputs and outputs.\n",
      " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
      " |          directly on a specific input or output to get the required gradients.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations. :attr:`grad_input` will only correspond to the inputs given\n",
      " |      as positional arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name: str, tensor: Union[torch.Tensor, NoneType], persistent: bool = True) -> None\n",
      " |      Adds a buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the module's state. Buffers, by\n",
      " |      default, are persistent and will be saved alongside parameters. This\n",
      " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
      " |      only difference between a persistent buffer and a non-persistent buffer\n",
      " |      is that the latter will not be a part of this module's\n",
      " |      :attr:`state_dict`.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |          persistent (bool): whether the buffer is part of this module's\n",
      " |              :attr:`state_dict`.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The input contains only the positional arguments given to the module.\n",
      " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name: str, param: Union[torch.nn.parameter.Parameter, NoneType]) -> None\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  share_memory(self: ~T) -> ~T\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(memory_format=torch.channels_last)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
      " |              format for 4D parameters and buffers in this module (keyword\n",
      " |              only argument)\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self: ~T, mode: bool = True) -> ~T\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self, set_to_none: bool = False) -> None\n",
      " |      Sets gradients of all model parameters to zero. See similar function\n",
      " |      under :class:`torch.optim.Optimizer` for more context.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
      " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  T_destination = ~T_destination\n",
      " |  \n",
      " |  __annotations__ = {'__call__': typing.Callable[..., typing.Any], '_ver...\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(transforms.Normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-massage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
